{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ASSIGNMNENT4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncNaB9JvNliS"
      },
      "source": [
        "#Assignment 4 - Reproducability of AlexNet\n",
        "\n",
        "We perform a reproduction study for the ImageNet Classification with Deep Convolutional Neural Network paper, more commonly known as AlexNet.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm8s1tdOP_iQ"
      },
      "source": [
        "#dependencies\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
        "from typing import Any\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from cv2 import imread\n",
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "path_jacob = '/content/drive/My Drive/Assignments/Assignment4/'\n",
        "path_theo = '/content/drive/My Drive/COMP 551/Assignments/Assignment4/'\n",
        "path = path_theo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3wNJuzcKS9x"
      },
      "source": [
        "To simplify the removal of convolutional layers and other tests we performed, the PyTorch implementation is copied directly from the open source code: https://github.com/pytorch/vision/blob/master/torchvision/models/alexnet.py\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-J5wLroNjgF"
      },
      "source": [
        "__all__ = ['AlexNet', 'alexnet']\n",
        "\n",
        "model_urls = {\n",
        "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-7be5be79.pth',\n",
        "}\n",
        "\n",
        "num_classes = 1000\n",
        "#This is the base architecture of the model\n",
        "base_features =   [nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)]\n",
        "base_pool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "base_classifier = [nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes)]\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, features, pool, classifier, num_classes: int = 1000,): \n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(*features)\n",
        "        self.avgpool = pool\n",
        "        self.classifier = nn.Sequential(*classifier)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "def alexnet(pretrained: bool = True, load_ablation = None, progress: bool = True,\n",
        "            features = base_features, pool=base_pool, classifier = base_classifier, **kwargs: Any) -> AlexNet:\n",
        "    r\"\"\"AlexNet model architecture from the\n",
        "    `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    model = AlexNet(features, pool, classifier, **kwargs)\n",
        "    if pretrained and load_ablation is None:\n",
        "        state_dict = load_state_dict_from_url(model_urls['alexnet'],\n",
        "                                              progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "        print('Loaded Base Model...')\n",
        "    elif pretrained and load_ablation != None:\n",
        "        model.load_state_dict(load_ablation)\n",
        "    return model\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59Acy4bLPzfk"
      },
      "source": [
        "## Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PV9_3oqZP249"
      },
      "source": [
        "def preprocess(input_image):\n",
        "  #reshaping the images for compatibility with PyTorch AlexNet\n",
        "  #normalizes the images like PyTorch AlexNet implementation \n",
        "  preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "  input_tensor = preprocess(input_image)\n",
        "  \n",
        "  input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
        "  return input_batch\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45DRZ1yQXOeq"
      },
      "source": [
        "Let's read in some images from the ILSVRC2012 ImageNet Dataset on which to test the pretrained model. Note that due to the impractically large size of the training set (~138 GB), and the lack of labels in the test set, all training and testing was done using the ILSVRC2012 ImageNet validation set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uhy61j_oQPxe"
      },
      "source": [
        "def load_images(img_count = 100, path = path):\n",
        "  read_file=open(path+\"ILSVRC2012_validation_ground_truth.txt\",'r')\n",
        "  ground_truth=[int(s.strip()) for s in read_file.readlines()]\n",
        "  image_list=[]\n",
        "  for i in range (1,img_count):\n",
        "    var= str(i).zfill(8)\n",
        "    string_to_read= path+'ILSVRC2012_img_val/ILSVRC2012_val_'+var+'.JPEG'\n",
        "    image=Image.open(string_to_read)\n",
        "    image_list.append(image.convert('RGB'))\n",
        "    if i%1000 == 0:\n",
        "      print(i)\n",
        "  return image_list, ground_truth\n",
        "\n",
        "images, ground_truth = load_images(img_count = 5000) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOw7dkbxXvD5"
      },
      "source": [
        "Note that the model predicts a category for an image. The output of this prediction is a string naming that category. For the purposes of evaluating the performance of the model, the model must output a numerical label. These values are obtained below:  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEZ87fIRRCeh"
      },
      "source": [
        "# Download ImageNet labels\n",
        "def load_labels(ground_truth = ground_truth):\n",
        "  !wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
        "  # Read the categories\n",
        "  with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "      categories = [s.strip() for s in f.readlines()]\n",
        "  label_names=open(path+\"map_clsloc.txt\",'r')\n",
        "  lines= label_names.readlines()\n",
        "  split_lines=list(map(lambda x: x.split(),lines))\n",
        "  #learn the names of the ground truths \n",
        "  conversion_dict_truth_to_name={}\n",
        "  for split_line in split_lines:\n",
        "    list_of_words= split_line[2].split(\"_\")\n",
        "    lower_case= list(map(lambda x: x.lower(),list_of_words))\n",
        "    conversion_dict_truth_to_name[int(split_line[1])]=\" \".join(lower_case)\n",
        "  #learn how to turn the names into the categories \n",
        "  name_to_int={}\n",
        "  for i in range(len(categories)):\n",
        "    name= categories[i]\n",
        "    name_to_int[name.lower()]=i #do i need to adjust from starting at zero or one???????\n",
        "  ####FINALLY CONVERT####\n",
        "  new_ground_truth=[]\n",
        "  for truth in ground_truth:\n",
        "    new_ground_truth.append(name_to_int[conversion_dict_truth_to_name[truth]])\n",
        "  return new_ground_truth\n",
        "  \n",
        "labels = load_labels()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMEl1oK7PrO9"
      },
      "source": [
        "## 1 Reproducing Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWCJyj_ZRQqq"
      },
      "source": [
        "def calculate_accuracy_top_one(top1_categories, new_ground_truth = labels):\n",
        "  #calculate the accuracy using the top 1 prediction\n",
        "  sum=0\n",
        "  for i in range(len(top1_categories)):\n",
        "    prob, cat= top1_categories[i]\n",
        "    #print(categories[ground_truth[i]])\n",
        "    if cat==new_ground_truth[i]:\n",
        "      sum=sum+1\n",
        "  return sum/len(top1_categories)\n",
        "\n",
        "\n",
        "def calculate_accuracy_top_five(top5_categories,new_ground_truth = labels):\n",
        "  #calculate the accuracy using the top 5 prediction (ie: if the true label is \n",
        "  #contained in top 5 out of 1000 predicted categories)\n",
        "  sum=0\n",
        "  for i in range(len(top5_categories)):\n",
        "    prob, cat= top5_categories[i]\n",
        "    #print(categories[ground_truth[i]])\n",
        "    if new_ground_truth[i] in cat:\n",
        "      sum=sum+1\n",
        "  return sum/len(top5_categories)\n",
        "\n",
        "def run_model(model, input_batch):\n",
        "  #forward propagates for testing \n",
        "  if torch.cuda.is_available():\n",
        "    input_batch = input_batch.to('cuda')\n",
        "    model.to('cuda')\n",
        "  with torch.no_grad():\n",
        "    output = model(input_batch)\n",
        "  return output\n",
        "\n",
        "def find_probabilities(output_scores): \n",
        "  #convert model output to probabilities using Softmax\n",
        "  probabilities = torch.nn.functional.softmax(output_scores[0], dim=0)\n",
        "  return probabilities\n",
        "\n",
        "def find_top_one(probabilities):\n",
        "  #return label and probability of top 1 prediction\n",
        "  top1_prob, top1_catid = torch.topk(probabilities,1)\n",
        "  return top1_prob[0], top1_catid[0]\n",
        "\n",
        "def find_top_five(probabilities):\n",
        "  #return label and probability of top 5 prediction\n",
        "  top5_prob, top5_catid = torch.topk(probabilities,5)\n",
        "  return top5_prob, top5_catid\n",
        "\n",
        "def simple_test(model, data = images):\n",
        "  #performs a simple test of a model using a list of images. \n",
        "  model.eval()\n",
        "  xtest=list(map(lambda x: preprocess(x),data))\n",
        "  output=list(map(lambda x: run_model(model, x), xtest))\n",
        "  probabilities= list(map(lambda x: find_probabilities(x),output))\n",
        "  top1_catids=list(map(lambda x: find_top_one(x),probabilities))# find_top_one(probabilities)\n",
        "  top5_catids=list(map(lambda x: find_top_five(x),probabilities))\n",
        "  print(\"Top 5 accuracy\")\n",
        "  print(calculate_accuracy_top_five(top5_catids))\n",
        "  print(\"Top 1 accuracy\")\n",
        "  print(calculate_accuracy_top_one(top1_catids))\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4FFSLtVWJ_e",
        "outputId": "565e86f5-790a-438c-9847-a9a319a55a62"
      },
      "source": [
        "model = alexnet(pretrained = True)\n",
        "simple_test(model)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Base Model...\n",
            "Top 5 accuracy\n",
            "0.7899579915983197\n",
            "Top 1 accuracy\n",
            "0.5717143428685737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvdAVskoop-R"
      },
      "source": [
        "weights = model.state_dict()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrOzN7GCliYw"
      },
      "source": [
        "##Ablation Studies\n",
        "We performed two successful ablation studies by removing the last two convolutional layers and their respective ReLU activations. We also tried to remove middle layers, but were unable to sufficiently retrain the models to produce a tolerable accuracy. Finally, we perfomed a series of other tests. The initialization of all of these models are listed at the bottom of the Notebook. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zh_BFbRxllak"
      },
      "source": [
        "def view_layers(model):\n",
        "  #display the model's layers\n",
        "  for name, param in model.named_parameters():\n",
        "      print('name: ', name)\n",
        "      print(type(param))\n",
        "      print('param.shape: ', param.shape)\n",
        "      print('param.requires_grad: ', param.requires_grad)\n",
        "      print('=====')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrCifCxknqXu"
      },
      "source": [
        "###Freeze model weights\n",
        "We attempted to remove middle layers by replacing them with various Identity Conv2d layers, which would simply output that layer's inputs. In order to finetune the model, that identity layer's weights would have to be frozen, so that it remains an identity, and does not become updated by stochastic gradient descent. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOqz7D1umOaa"
      },
      "source": [
        "def freeze_layers(model, unfrozen_param = output):\n",
        "  for name, param in model.named_parameters():\n",
        "    if name in unfrozen_param:\n",
        "        param.requires_grad = True\n",
        "    else:\n",
        "        param.requires_grad = False"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-CWOrgFntss"
      },
      "source": [
        "## Let's try to remove a layer: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1tS0-9et37A"
      },
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "def remove_layer(weights, *layers):\n",
        "  #Removes layer weights from the ordered dictionary of network weights\n",
        "  #by removing the corresponding key value pair\n",
        "  weights = weights.copy()\n",
        "  print('Removing Layer:')\n",
        "  for key in layers:\n",
        "    print(f'{key}: {weights[key].shape}')\n",
        "    del weights[key]\n",
        "  print('\\n')\n",
        "  return weights\n",
        "\n",
        "def show_new_dims(weights):\n",
        "  #list the model's architecture\n",
        "  print('\\nRetained Weights:')\n",
        "  for key in weights.keys():\n",
        "    print(f'{key}: {weights[key].shape}')\n",
        "\n",
        "def rename_key(dictionary, old_key,new_key):\n",
        "  #renames a key in the ordered dictionary of weights\n",
        "  #necessary when completely removing a middle layer \n",
        "  #from Alexnet\n",
        "  dictionary[new_key] = dictionary[old_key]\n",
        "  del dictionary[old_key]\n",
        "  return dictionary\n",
        "\n",
        "def reorder(dictionary, new_order):\n",
        "  #after renaming the keys, reorders the dictionary\n",
        "  d = dict(dictionary)\n",
        "  ordered = OrderedDict()\n",
        "  for k in new_order:\n",
        "    ordered[k] = d[k]\n",
        "  return ordered\n",
        "\n",
        "def make_layer_dumb(model,layer, shape = (256,384,3,3)):\n",
        "  #makes a layer dumb by creating an Identity layer. \n",
        "  #replaces  layer's weights with a tensor composed of (kernel size x kernel size)\n",
        "  #matrices of 0s with a 1 at their center\n",
        "  weights = model.state_dict().copy()\n",
        "  new_tensor= np.zeros(shape)\n",
        "  for x in range(shape[0]):\n",
        "    for y in range(shape[1]):\n",
        "      new_tensor[x][y][1][1]=1\n",
        "  weights[layer] = torch.tensor(new_tensor)\n",
        "  return weights\n",
        "\n",
        "new_model = alexnet(load_ablation=weights)\n",
        "new_weights = remove_layer(new_model.state_dict(), 'features.10.weight', 'features.10.bias')\n",
        "show_new_dims(new_weights)\n",
        "\n",
        "# new_weights = rename_key(new_weights, 'features.10.weight','features.8.weight')\n",
        "# new_weights = rename_key(new_weights, 'features.10.bias','features.8.bias')\n",
        "# # new_weights = reorder(new_weights, new_order)\n",
        "# show_new_dims(new_weights)\n",
        "\n",
        "# # new_weights = make_layer_dumb(new_model,'classifier.6.weight','classifier.6.bias')\n",
        "# show_new_dims(new_weights)\n",
        "\n",
        "# layer = ['features.8.weight', 'features.8.bias']\n",
        "# new_model = alexnet(load_ablation=weights)\n",
        "# new_weights = make_layer_dumb2(new_model, 12, layer[0])\n",
        "# freeze_layers(new_model, layer)\n",
        "# show_new_dims(new_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHJjtTtmRcDK"
      },
      "source": [
        "##Initialize our New Model\n",
        "New model architecture found below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VafL0Q6NsZw6"
      },
      "source": [
        "num_classes = 1000\n",
        "features_ =  [nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)]\n",
        "            \n",
        "pooling_ = nn.AdaptiveAvgPool2d((6, 6))\n",
        "\n",
        "classifier_ = [nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.Linear(4096, num_classes)]\n",
        "\n",
        "\n",
        "changed_weights = True\n",
        "if changed_weights == True:\n",
        "  #set weights to new weights obtained above (for removing layer) \n",
        "  weights = new_weights \n",
        "\n",
        "model_abl = alexnet(pretrained = True, load_ablation = weights, features = features_, pool = pooling_, classifier = classifier_ )\n",
        "simple_test(model_abl)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0psCec5-ZF8N"
      },
      "source": [
        "##Fine-Tuning New Model\n",
        "\n",
        "Train the model using the new architecture. Optimization is done using SGD against a cross entropy loss criteria. Code was obtained from tutorial below, and was edited to suit the purposes of this study. \n",
        "\n",
        "https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9go3yirNZFfH"
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=5):\n",
        "    since = time.time()\n",
        "    val_acc_history = []\n",
        "    #copy the weights\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    \n",
        "    #iterate over epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "        print()\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sc-iviAAhZlP"
      },
      "source": [
        "Load New Data for Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5860mNJiZkr"
      },
      "source": [
        "input_size=224\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(input_size),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])}\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIKa_X1jfqqi"
      },
      "source": [
        "#Default Hyperparameters\n",
        "batch_size = 128\n",
        "lr_ = 0.05\n",
        "momentum_ = 0.9\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XN10XfpUha-m",
        "outputId": "822a2e4b-cd37-4ea2-de99-e886ebbd53e9"
      },
      "source": [
        "data_dir=path\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
        "print(image_datasets)\n",
        "# Create training and validation dataloaders\n",
        "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=2) for x in ['train', 'val']}"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'train': Dataset ImageFolder\n",
            "    Number of datapoints: 35003\n",
            "    Root location: /content/drive/My Drive/COMP 551/Assignments/Assignment4/train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear)\n",
            "               RandomHorizontalFlip(p=0.5)\n",
            "               ToTensor()\n",
            "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "           ), 'val': Dataset ImageFolder\n",
            "    Number of datapoints: 5000\n",
            "    Root location: /content/drive/My Drive/COMP 551/Assignments/Assignment4/val\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Resize(size=224, interpolation=bilinear)\n",
            "               CenterCrop(size=(224, 224))\n",
            "               ToTensor()\n",
            "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "           )}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjfRZjTxFVu9"
      },
      "source": [
        "Train and Test a Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmlGurqiFU9I"
      },
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Setup the loss fxn\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Train and evaluate\n",
        "\n",
        "#HYPER PARAMETERS\n",
        "lr_ = 0.05\n",
        "momentum_ = 0.9\n",
        "\n",
        "model_ft = model_abl\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "params_to_update = model_ft.parameters()\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=lr_, momentum=momentum_)\n",
        "\n",
        "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft)\n",
        "simple_test(model_ft)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j01KNtUihb0k"
      },
      "source": [
        "##Hyperparameter Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgWD8CPmdfuh"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Setup the loss fxn\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Train and evaluate\n",
        "\n",
        "#default from paper\n",
        "batch_size = 128\n",
        "lr_ = 0.05\n",
        "momentum_ = 0.9\n",
        "\n",
        "momentum = [0.09, 0.9, 9]\n",
        "lr = [0.0005, 0.05, 0.5]\n",
        "batch_sizes = [8, 128, 500]\n",
        "\n",
        "#GRID_SEARCH OVER HYPER PARAMETERS\n",
        "hyperparameters  = momentum \n",
        "results = []\n",
        "\n",
        "for h in hyperparameters:\n",
        "  dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=2) for x in ['train', 'val']}\n",
        "  model_ft = alexnet(pretrained = True)\n",
        "  model_ft = model_ft.to(device)\n",
        "\n",
        "  params_to_update = model_ft.parameters()\n",
        "  optimizer_ft = optim.SGD(params_to_update, lr=lr_, momentum=h)\n",
        "\n",
        "  model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft)\n",
        "  results.append(hist)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcT7EOuJZVf3"
      },
      "source": [
        "##The architectures we used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "916qzLdTjcg-",
        "outputId": "4bfe61cb-e6b8-4ab1-e5ac-f00a83b86527"
      },
      "source": [
        "#ablation last layer\n",
        "features_ = [nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)]\n",
        "            \n",
        "pooling_ = nn.AdaptiveAvgPool2d((6, 6))\n",
        "\n",
        "classifier_ = [nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPbaKHkr8ATV"
      },
      "source": [
        "#ablation of last two convolutional layers \n",
        "features_ = [nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)]\n",
        "            \n",
        "pooling_ = nn.AdaptiveAvgPool2d((4, 6))\n",
        "\n",
        "classifier_ = [nn.Dropout(),\n",
        "            nn.Linear(384 * 4 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cCEDcuD8KrI"
      },
      "source": [
        "#replace max pool with average pool\n",
        "num_classes = 1000\n",
        "features_ = [nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AvgPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AvgPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AvgPool2d(kernel_size=3, stride=2),\n",
        "            \n",
        "pooling_ = nn.AdaptiveAvgPool2d((4, 6))\n",
        "\n",
        "classifier_ = [nn.Dropout(),\n",
        "            nn.Linear(384 * 4 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BjGvTVZZeyB"
      },
      "source": [
        "#non-overlapping max pool\n",
        "num_classes = 1000\n",
        "features_ = [nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            \n",
        "pooling_ = nn.AdaptiveAvgPool2d((4, 6))\n",
        "\n",
        "classifier_ = [nn.Dropout(),\n",
        "            nn.Linear(384 * 4 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcag4_1UZsfE"
      },
      "source": [
        "#sigmoid activation\n",
        "features_ = [nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.Simoid(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.Simoid(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.Simoid(),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.Simoid(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.Sigmoid(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)]\n",
        "            \n",
        "pooling_ = nn.AdaptiveAvgPool2d((6, 6))\n",
        "\n",
        "classifier_ = [nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.Simoid(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.Simoid(),\n",
        "            nn.Linear(4096, num_classes)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX9xIXNhaBva"
      },
      "source": [
        "#tanh activation\n",
        "features_ = [nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.Tanh(),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.Tanh(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.Tanh(), \n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)]\n",
        "            \n",
        "pooling_ = nn.AdaptiveAvgPool2d((6, 6))\n",
        "\n",
        "classifier_ = [nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(4096, num_classes)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OC1ePRJexgQ5"
      },
      "source": [
        " #remove dropout\n",
        " features_ = [nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)]\n",
        "\n",
        "pooling_ = nn.AdaptiveAvgPool2d((4, 6))\n",
        "\n",
        "classifier_ = [\n",
        "            nn.Linear(256 * 4 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes)]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}